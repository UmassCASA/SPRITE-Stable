{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "from config import Config\n",
    "from dgmr import DGMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT_FRAMES = 4\n",
    "NUM_TARGET_FRAMES = 4\n",
    "TOTAL_FRAMES = NUM_INPUT_FRAMES + NUM_TARGET_FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real test data\n",
    "class NetCDFDataset(torch.utils.data.dataset.Dataset):\n",
    "    \"\"\"\n",
    "    Typically, dataset returns an individual item from the dataset in __getitem__ method.\n",
    "    Also, it should return the number of items in the dataset in __len__ method.\n",
    "\n",
    "    Here, dataset returns a batch of frames in __getitem__ method, therefore __len__ method returns the number of batches.\n",
    "    Also, DGMRDataModule should have batch_size=1, since we are returning a batch of frames in __getitem__ method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        split,\n",
    "        num_epochs,\n",
    "        batches_per_epoch=5,\n",
    "        batch_offset=0,\n",
    "        start_day=\"20160301\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.local_folder_path = os.path.join(Config.DATA_DIR, split)\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batches_per_epoch = batches_per_epoch\n",
    "        self.batch_offset = batch_offset\n",
    "        self.all_files = self._get_all_files(start_day)\n",
    "\n",
    "        # Adjust total_batches based on the split type\n",
    "        if self.split == \"train\":\n",
    "            # For training, calculate total_batches dynamically based on the number of epochs and desired batches per epoch\n",
    "            self.total_batches = len(self.all_files) // TOTAL_FRAMES\n",
    "\n",
    "        else:\n",
    "            # For validation (and potentially test), limit to first n batches if split is not training\n",
    "            self.total_batches = min(len(self.all_files) // TOTAL_FRAMES, self.batches_per_epoch)\n",
    "\n",
    "        print(f\"For split: {split}: total_batches: {self.total_batches} | number of files: {len(self.all_files)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return size of the data set for DataLoader, but if Dataset gives complete batches\n",
    "        and not individual items from the dataset, then it should return total number of batches\n",
    "        \"\"\"\n",
    "        if self.split == \"train\":\n",
    "            # Only limit the length for training to process batches_per_epoch batches each epoch\n",
    "            return self.batches_per_epoch\n",
    "        return self.total_batches\n",
    "\n",
    "    def _get_all_files(self, start_day=\"20160301\"):\n",
    "        limit = float(\"inf\")\n",
    "        if self.split == \"test\" or self.split == \"validation\":\n",
    "            limit = self.batches_per_epoch * TOTAL_FRAMES\n",
    "\n",
    "        all_files = []\n",
    "\n",
    "        day_folders = sorted(os.listdir(self.local_folder_path))\n",
    "        # Remove the days before the start_day\n",
    "        day_folders = [d for d in day_folders if d >= start_day]\n",
    "\n",
    "        for day_folder in day_folders:\n",
    "            day_folder_path = os.path.join(self.local_folder_path, day_folder)\n",
    "            if os.path.isdir(day_folder_path):\n",
    "                files = sorted(os.listdir(day_folder_path))\n",
    "                all_files.extend([os.path.join(day_folder_path, f) for f in files])\n",
    "                if len(all_files) >= limit:\n",
    "                    break\n",
    "        return all_files\n",
    "\n",
    "    def _check_batch(self, frames, batch_idx, frame_type):\n",
    "        # Check for abnormal values\n",
    "        if (frames >= 65535).any():\n",
    "            frames[frames >= 65535] = 0  # 65534 What should be the value?\n",
    "\n",
    "        # Check for NaN values\n",
    "        if np.isnan(frames).any():\n",
    "            raise ValueError(f\"NaN values found in {frame_type} frames of batch {batch_idx}\")\n",
    "\n",
    "        # Check for negative values\n",
    "        if (frames < 0).any():\n",
    "            raise ValueError(f\"Negative values found in {frame_type} frames of batch {batch_idx}\")\n",
    "\n",
    "        # Check if all frames are not a type of masked array\n",
    "        if all([isinstance(f, np.ma.MaskedArray) for f in frames]):\n",
    "            raise ValueError(f\"Frame(s) of batch {batch_idx} have masked array\")\n",
    "\n",
    "    def _load_frame(self, file_path):\n",
    "        print(f\"Loading file: {file_path}\")\n",
    "        with Dataset(file_path, \"r\") as nc_data:\n",
    "            return np.ma.filled(nc_data.variables[\"RRdata\"][:], 0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns one sequence(batch) of frames\"\"\"\n",
    "\n",
    "        # Adjust index based on the batch offset\n",
    "        actual_idx = (self.batch_offset + idx) % self.total_batches\n",
    "        start_idx = actual_idx * TOTAL_FRAMES\n",
    "        end_idx = min(start_idx + TOTAL_FRAMES, len(self.all_files))\n",
    "        frame_paths = self.all_files[start_idx:end_idx]\n",
    "\n",
    "        frames = [self._load_frame(fp) for fp in frame_paths]\n",
    "        input_frames = np.stack(frames[:NUM_INPUT_FRAMES])\n",
    "        target_frames = np.stack(frames[NUM_INPUT_FRAMES:])\n",
    "\n",
    "        # Checks for the entire batch\n",
    "        self._check_batch(input_frames, idx, \"input\")\n",
    "        self._check_batch(target_frames, idx, \"target\")\n",
    "\n",
    "        return input_frames, target_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Initialize and load model\n",
    "model = DGMR(\n",
    "    forecast_steps=4,\n",
    "    input_channels=1,\n",
    "    output_shape=256,\n",
    "    latent_channels=768,\n",
    "    context_channels=384,\n",
    "    num_samples=3,\n",
    "    visualize=True,  # Ensure this is True\n",
    ").to(device)\n",
    "\n",
    "# Evaluate the model on real test data\n",
    "model.eval()\n",
    "print(\"Model set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "def plot_data_and_save(data, title, directory):\n",
    "    batch_size, time_steps, channels, height, width = data.shape\n",
    "    vmin = 0  # Minimum value of your data range (e.g., 0 mm/hr)\n",
    "\n",
    "    # Calculate vmax across the entire dataset to ensure consistent color mapping\n",
    "    # vmax = torch.max(data) if torch.max(data) > 128 else 128\n",
    "    vmax = torch.max(data) if torch.max(data) > 10 else 10\n",
    "\n",
    "    fig, axs = plt.figure(figsize=(time_steps * 4, 4)), []\n",
    "    for i in range(time_steps):\n",
    "        ax = fig.add_subplot(1, time_steps, i + 1)\n",
    "        frame_data = data[0, i, 0].cpu().detach().numpy()  # Assuming data is a torch Tensor\n",
    "        im = ax.imshow(frame_data, cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "        axs.append(ax)\n",
    "\n",
    "        ax.set_title(f\"{title} - Time {i + 1}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Add one color bar for the entire figure\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", fraction=0.1, pad=0.04, label=\"RRdata (mm/hr)\")\n",
    "\n",
    "    # Optionally, add labels for max and min values\n",
    "    # This can be done by using text annotations if needed or included in the colorbar label\n",
    "    # For simplicity, it's included in the colorbar label above. Modify as needed for different requirements.\n",
    "\n",
    "    save_path = os.path.join(directory, f\"{title.replace(' ', '_')}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "\n",
    "def visualize_step(\n",
    "    tensorboard_writer,\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    y_hat: torch.Tensor,\n",
    "    batch_idx: int,\n",
    "    step: str,\n",
    "    input_channels: int,\n",
    ") -> None:\n",
    "    images = x[0].cpu().detach()\n",
    "    future_images = y[0].cpu().detach()\n",
    "    generated_images = y_hat[0].cpu().detach()\n",
    "    for i, t in enumerate(images):\n",
    "        t = [torch.unsqueeze(img, dim=0) for img in t]\n",
    "        image_grid = torchvision.utils.make_grid(t, nrow=input_channels)\n",
    "        tensorboard_writer.add_image(f\"{step}/Input_Image_Stack_Frame_{i}\", image_grid, global_step=batch_idx)\n",
    "    for i, t in enumerate(future_images):\n",
    "        t = [torch.unsqueeze(img, dim=0) for img in t]\n",
    "        image_grid = torchvision.utils.make_grid(t, nrow=input_channels)\n",
    "        tensorboard_writer.add_image(f\"{step}/Target_Image_Stack_Frame_{i}\", image_grid, global_step=batch_idx)\n",
    "    for i, t in enumerate(generated_images):\n",
    "        t = [torch.unsqueeze(img, dim=0) for img in t]\n",
    "        image_grid = torchvision.utils.make_grid(t, nrow=input_channels)\n",
    "        tensorboard_writer.add_image(f\"{step}/Predicted_Image_Stack_Frame_{i}\", image_grid, global_step=batch_idx)\n",
    "\n",
    "    print(\"Visualized a batch of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"DGMR-V1_20240426_0127\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "checkpoint_path = os.path.join(Config.ROOT_DIR, f\"output/models/{model_name}.ckpt\")\n",
    "\n",
    "plot_output_path = os.path.join(Config.ROOT_DIR, f\"output/visualize_predicted_results/{model_name}/{timestamp}\")\n",
    "tensorboard_output_path = os.path.join(plot_output_path, \"TensorBoard\")\n",
    "\n",
    "os.makedirs(tensorboard_output_path, exist_ok=True)\n",
    "os.makedirs(plot_output_path, exist_ok=True)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test data\n",
    "test_data_loader = DataLoader(\n",
    "    NetCDFDataset(split=\"train\", num_epochs=1, start_day=\"20180908\"),\n",
    "    batch_size=1,\n",
    ")\n",
    "print(\"Test data loaded successfully\")\n",
    "\n",
    "tensorboard_writer = SummaryWriter(tensorboard_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (test_inputs, test_targets) in enumerate(test_data_loader):\n",
    "        print(\"Processing a batch of test data\")\n",
    "        print(f\"Input shape: {test_inputs.shape}\")\n",
    "\n",
    "        # Move data to device\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_targets = test_targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        test_outputs = model(test_inputs)\n",
    "\n",
    "        # Visualization\n",
    "        plot_data_and_save(test_inputs, \"Real Test Input Data\", directory=plot_output_path)\n",
    "        plot_data_and_save(test_outputs, \"Generated Data\", directory=plot_output_path)\n",
    "        plot_data_and_save(test_targets, \"Real Test Target Data\", directory=plot_output_path)\n",
    "\n",
    "        # Visualization using modified visualize_step\n",
    "        # visualize_step(\n",
    "        #     tensorboard_writer,\n",
    "        #     test_inputs,\n",
    "        #     test_targets,\n",
    "        #     test_outputs,\n",
    "        #     batch_idx,\n",
    "        #     \"test\",\n",
    "        #     model.input_channels,  # Assuming this is defined in your model\n",
    "        # )\n",
    "        break  # Remove this line to process the entire test set\n",
    "\n",
    "# print(\n",
    "#     f\"tensorboard --logdir=/work/pi_mzink_umass_edu/SPRITE/skillful_nowcasting/{tensorboard_output_path[2:]} & ./ngrok http 6006\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgmr-casa-venv",
   "language": "python",
   "name": "dgmr-casa-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
