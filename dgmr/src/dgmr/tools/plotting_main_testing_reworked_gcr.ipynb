{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use animate \n",
    "Can use plot_geography or plot_map_cartopy for map under the hood\n",
    "Observed mm/dd/yyyy THR:MM UTC ---> Forecast +5 min ---> Forecast +10 min \n",
    "\n",
    "https://pysteps.readthedocs.io/en/latest/pysteps_reference/visualization.html\n",
    "\n",
    "\n",
    "1. Import packages\n",
    "2. Load data\n",
    "3. Plot data\n",
    "A. Observed data\n",
    "B. DGMR 273\n",
    "C. DGMR 378\n",
    "D. STEPS\n",
    "E. LINDA\n",
    "4. 30 minute steps\n",
    "\n",
    "\n",
    "Resolve problem with weird background\n",
    "Create with 30 minute steps and 5 minute steps\n",
    "\n",
    "Check if cartopy working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:14:44.527838Z",
     "iopub.status.busy": "2024-11-14T03:14:44.522207Z",
     "iopub.status.idle": "2024-11-14T03:14:58.653806Z",
     "shell.execute_reply": "2024-11-14T03:14:58.652673Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sprite_core.config import Config\n",
    "from dgmr import DGMR\n",
    "import random\n",
    "import pysteps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from pysteps.visualization import plot_precip_field\n",
    "\n",
    "from CASADataset import CASADataset\n",
    "from NIMRODDataset import NIMRODDataset\n",
    "\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:14:58.661352Z",
     "iopub.status.busy": "2024-11-14T03:14:58.660584Z",
     "iopub.status.idle": "2024-11-14T03:14:58.667785Z",
     "shell.execute_reply": "2024-11-14T03:14:58.666991Z"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(model_name):\n",
    "    start_time = time.time()\n",
    "    yield\n",
    "    end_time = time.time()\n",
    "    print(f\"{model_name} | Elapsed time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:14:58.671774Z",
     "iopub.status.busy": "2024-11-14T03:14:58.671443Z",
     "iopub.status.idle": "2024-11-14T03:15:06.277831Z",
     "shell.execute_reply": "2024-11-14T03:15:06.276676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "NUM_INPUT_FRAMES = 4\n",
    "NUM_TARGET_FRAMES = 18\n",
    "TOTAL_FRAMES = NUM_INPUT_FRAMES + NUM_TARGET_FRAMES\n",
    "\n",
    "RANDOM_SAMPLE = False\n",
    "USE_CASA = True\n",
    "# If false, can only execute using the sbatch as it allows to request RAM for the data without OOM.\n",
    "metadata = None\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if USE_CASA:\n",
    "    test_data_loader = DataLoader(\n",
    "        CASADataset(split=\"test\", include_datetimes=True, data_dir=Config.DATA_DIR), batch_size=1\n",
    "    )\n",
    "else:\n",
    "    test_data_loader = DataLoader(NIMRODDataset(split=\"validation\"), batch_size=1)\n",
    "\n",
    "# Randomly sample 5 indices from test data\n",
    "if RANDOM_SAMPLE:\n",
    "    sampled_ids = random.sample(range(len(test_data_loader.dataset)), 5)\n",
    "    print(\"Sampled ids:\", sampled_ids)\n",
    "\n",
    "else:\n",
    "    sampled_ids = [116, 198, 273, 145, 148]\n",
    "    print(\"Predefined ids:\", sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    # [\"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26840027-DGMR–CASA-N1-G4-P32_GS6_BS32-PW1.0_E500_GLR5e-5_DLR2e-4\", \"last\"],\n",
    "    # [\"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26840028-DGMR–CASA-N1-G4-P32_GS6_BS32-PW24.0_E500_GLR5e-5_DLR2e-4\", \"last\"],\n",
    "    [\n",
    "        \"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26840029-DGMR–CASA-N1-G4-P32_GS6_BS32-PW64.0_E500_GLR5e-5_DLR2e-4\",\n",
    "        \"last\",\n",
    "    ],\n",
    "    [\n",
    "        \"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26982810-DGMR–CASA-128-N2-G4-P32_GS6_BS32-PW24_E500_GLR5e-5_DLR2e-4\",\n",
    "        \"last\",\n",
    "    ],\n",
    "    # [\"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26840030-DGMR–CASA-N1-G4-P32_GS6_BS32-PW128.0_E500_GLR5e-5_DLR2e-4\", \"last\"],\n",
    "    # [\"/work/pi_mzink_umass_edu/SPRITE/outputs/GridCellLoss_500/J26840031-DGMR–CASA-N1-G4-P32_GS6_BS32-PW203.2_E500_GLR5e-5_DLR2e-4\", \"last\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:06.290995Z",
     "iopub.status.busy": "2024-11-14T03:15:06.290089Z",
     "iopub.status.idle": "2024-11-14T03:15:06.298642Z",
     "shell.execute_reply": "2024-11-14T03:15:06.298256Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = \"CASA\" if USE_CASA else \"NIMROD\"\n",
    "plot_output_path = os.path.join(\n",
    "    Config.OUTPUTS_DIR,\n",
    "    f\"GridCellLoss_500/visualize_predicted_results/{datetime.now().strftime('%Y%m%d_%H%M')}-{dataset}\",\n",
    ")\n",
    "os.makedirs(plot_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:06.301300Z",
     "iopub.status.busy": "2024-11-14T03:15:06.301113Z",
     "iopub.status.idle": "2024-11-14T03:15:14.437701Z",
     "shell.execute_reply": "2024-11-14T03:15:14.437185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "models = {}\n",
    "for path_to_dir, model_name in model_names:\n",
    "    print(f\"Loading model {model_name}\")\n",
    "    model = DGMR(\n",
    "        forecast_steps=NUM_TARGET_FRAMES,\n",
    "        input_channels=1,\n",
    "        output_shape=256,\n",
    "        latent_channels=768,\n",
    "        context_channels=384,\n",
    "        num_samples=3,\n",
    "        visualize=True,\n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(Config.ROOT_DIR, os.path.join(path_to_dir, f\"{model_name}.ckpt\"))\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # Find the PWC value from the path\n",
    "    pwc_match = re.search(r\"PW(\\d+\\.?\\d*)\", path_to_dir)\n",
    "    pwc_value = pwc_match.group(1) if pwc_match else \"Unknown\"\n",
    "\n",
    "    # Create shorter model name with GCR (Grid Cell Regularization) prefix\n",
    "    model_name = f\"GCR_{pwc_value}\"\n",
    "    models[model_name] = model\n",
    "\n",
    "    print(f\"Model {model_name} loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:14.441669Z",
     "iopub.status.busy": "2024-11-14T03:15:14.440704Z",
     "iopub.status.idle": "2024-11-14T03:15:14.457173Z",
     "shell.execute_reply": "2024-11-14T03:15:14.456741Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_up_axes(ax):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # Remove the spines\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "def calculate_pixel_percentage(data_slice, levels):\n",
    "    \"\"\"\n",
    "    Calculate and print the percentage of pixels in each range of levels.\n",
    "\n",
    "    Args:\n",
    "        data_slice (2D numpy array): The input data slice to analyze.\n",
    "        levels (list): The precipitation intensity levels.\n",
    "\n",
    "    Returns:\n",
    "        percentages (list): The percentage of pixels in each range.\n",
    "    \"\"\"\n",
    "    # Flatten the data slice to a 1D array for easier processing\n",
    "    flat_data = data_slice.flatten()\n",
    "\n",
    "    # Initialize an empty list to store percentages\n",
    "    percentages = []\n",
    "\n",
    "    # Calculate percentages for each range defined by levels\n",
    "    for i in range(len(levels) - 1):\n",
    "        lower_bound = levels[i]\n",
    "        upper_bound = levels[i + 1]\n",
    "        # Count the number of pixels within the current range\n",
    "        count = np.sum((flat_data >= lower_bound) & (flat_data < upper_bound))\n",
    "        # Calculate the percentage of pixels in the current range\n",
    "        percentage = (count / flat_data.size) * 100\n",
    "        percentages.append(percentage)\n",
    "        # Print the range and rounded percentage\n",
    "        print(f\"{lower_bound:.1f}-{upper_bound:.1f}: {percentage:.1f}%\")\n",
    "\n",
    "    # For the upper bound (last bin)\n",
    "    count_above = np.sum(flat_data >= levels[-1])\n",
    "    percentage_above = (count_above / flat_data.size) * 100\n",
    "    percentages.append(percentage_above)\n",
    "    # Print the upper bound range and rounded percentage\n",
    "    print(f\">= {levels[-1]:.1f}: {percentage_above:.1f}%\")\n",
    "\n",
    "    return percentages\n",
    "\n",
    "\n",
    "def create_metadata(x0_resized, y0_resized):\n",
    "    \"\"\"\n",
    "    projection  PROJ.4-compatible projection definition\n",
    "    x1          x-coordinate of the lower-left corner of the data raster\n",
    "    y1          y-coordinate of the lower-left corner of the data raster\n",
    "    x2          x-coordinate of the upper-right corner of the data raster\n",
    "    y2          y-coordinate of the upper-right corner of the data raster\n",
    "    yorigin     a string specifying the location of the first element in the data raster w.r.t. y-axis: ‘upper’ = upper border, ‘lower’ = lower border\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"projection\": \"+proj=longlat +datum=WGS84 +no_defs\",  # Example projection, update as needed\n",
    "        \"x1\": x0_resized[0],  # Lower-left x-coordinate\n",
    "        \"y1\": y0_resized[-1],  # Lower-left y-coordinate (last element due to 'upper' origin)\n",
    "        \"x2\": x0_resized[-1],  # Upper-right x-coordinate\n",
    "        \"y2\": y0_resized[0],  # Upper-right y-coordinate (first element due to 'upper' origin)\n",
    "        \"yorigin\": \"upper\",  # Assuming the y-axis starts from the top\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# Load the coordinates from the original 366x350 netCDF file\n",
    "nc_file = Dataset(\"/work/pi_mzink_umass_edu/SPRITE/CASAData/test/20221221/20221221_062335.nc\", \"r\")\n",
    "x0_full, y0_full = nc_file.variables[\"x0\"][:], nc_file.variables[\"y0\"][:]\n",
    "nc_file.close()\n",
    "\n",
    "# Crop the coordinates to the 350x350 grid\n",
    "x0_cropped = x0_full[8:-8]\n",
    "y0_cropped = y0_full[8:-8]\n",
    "\n",
    "# Resize to 256x256\n",
    "x0_resized = np.linspace(x0_cropped.min(), x0_cropped.max(), 256)\n",
    "y0_resized = np.linspace(y0_cropped.min(), y0_cropped.max(), 256)\n",
    "\n",
    "metadata = create_metadata(x0_resized, y0_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:14.460793Z",
     "iopub.status.busy": "2024-11-14T03:15:14.459853Z",
     "iopub.status.idle": "2024-11-14T03:15:14.466732Z",
     "shell.execute_reply": "2024-11-14T03:15:14.466322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create custom colormap\n",
    "\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "\n",
    "class ColormapConfig:\n",
    "    def __init__(self):\n",
    "        self.cmap = None\n",
    "        self.norm = None\n",
    "        self.clevs = None\n",
    "        self.bounds = None\n",
    "\n",
    "        self.build_colormap()\n",
    "\n",
    "    def build_colormap(self):\n",
    "        # Define the colormap boundaries and colors\n",
    "\n",
    "        # Eric's custom colormap\n",
    "        # color_list = [\n",
    "        #     \"#4cecec\",\n",
    "        #     \"#44c6f0\",\n",
    "        #     \"#429afb\",\n",
    "        #     \"#3431fd\",\n",
    "        #     \"#40f600\",\n",
    "        #     \"#3ada0b\",\n",
    "        #     \"#2eb612\",\n",
    "        #     \"#2a8a0f\",\n",
    "        #     \"#f8f915\",\n",
    "        #     \"#e9d11c\",\n",
    "        #     \"#dcb11f\",\n",
    "        #     \"#bd751f\",\n",
    "        #     \"#f39a9c\",\n",
    "        #     \"#f23a43\",\n",
    "        #     \"#da1622\",\n",
    "        #     \"#a90c1b\",\n",
    "        #     \"#fa31ff\",\n",
    "        #     \"#d32ada\",\n",
    "        #     \"#9f1fa3\",\n",
    "        #     \"#751678\",\n",
    "        #     \"#ffffff\",\n",
    "        #     \"#c1bdff\",\n",
    "        #     \"#c5ffff\",\n",
    "        #     \"#fcfec0\",\n",
    "        #     \"#fcfec0\"\n",
    "        # ]\n",
    "\n",
    "        # self.clevs = [1, 6.35, 12.7, 19.05, 25.4, 31.75, 38.1, 44.45, 50.8, 57.15, 63.5, 69.85, 76.2, 82.55, 88.9, 95.25, 101.6, 114.3, 127.0, 139.7, 152.4, 165.1, 177.8, 190.5, 203.2]\n",
    "        # self.bounds = [1, 12.7, 25.4, 38.1, 50.8, 63.5, 76.2, 88.9, 101.6, 127.0, 152.4, 177.8, 203.2]\n",
    "\n",
    "        # Shortened version of Eric's custom colormap\n",
    "        color_list = [\n",
    "            \"#44c6f0\",\n",
    "            \"#429afb\",\n",
    "            \"#3431fd\",\n",
    "            \"#f8f915\",\n",
    "            \"#dcb11f\",\n",
    "            \"#bd751f\",\n",
    "            \"#f23a43\",\n",
    "            \"#da1622\",\n",
    "            \"#a90c1b\",\n",
    "        ]\n",
    "\n",
    "        self.clevs = [1, 6.35, 12.7, 19.05, 25.4, 31.75, 38.1, 44.45, 50.8]  # 9\n",
    "        self.bounds = [1, 12.7, 25.4, 38.1, 50.8]\n",
    "\n",
    "        self.cmap = colors.ListedColormap(color_list)\n",
    "        # self.cmap.set_over(\"#fcfec0\") # from Eric's custom colormap\n",
    "        self.cmap.set_over(\"darkmagenta\")\n",
    "        self.cmap.set_under(\"none\")\n",
    "        self.cmap.set_bad(\"gray\", alpha=0.5)\n",
    "        self.norm = colors.BoundaryNorm(self.clevs, self.cmap.N)\n",
    "        self.cmap.name = \"Custom Colormap\"\n",
    "\n",
    "\n",
    "cmap_config = ColormapConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify whether the plots are related to the colorbar\n",
    "Metadata geography\n",
    "Graphing of 4 before, and 16 after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:14.469360Z",
     "iopub.status.busy": "2024-11-14T03:15:14.469173Z",
     "iopub.status.idle": "2024-11-14T03:15:14.482688Z",
     "shell.execute_reply": "2024-11-14T03:15:14.482272Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_data_and_save(\n",
    "    inputs, targets, outputs, metadata, directory, idx, moment_datetime=\"Unspecified\", title=None, model_subset_idx=0\n",
    "):\n",
    "    # Select the appropriate 2D slice\n",
    "    input_slices = inputs[0, -4:, 0, :, :].cpu().numpy()\n",
    "    target_slices = [targets[0, i, 0, :, :].cpu().numpy() for i in range(min(4, targets.shape[1]))]\n",
    "\n",
    "    # Adjusted figsize for the plot\n",
    "    fig = plt.figure(figsize=(51, 36))  # wxh\n",
    "\n",
    "    # Get subset of models (4 at a time)\n",
    "    model_items = list(outputs.items())\n",
    "    start_idx = model_subset_idx * 4\n",
    "    end_idx = min(start_idx + 4, len(model_items))\n",
    "    current_outputs = dict(model_items[start_idx:end_idx])\n",
    "\n",
    "    # Keep consistent 5-row layout\n",
    "    gs1 = fig.add_gridspec(1, 4, bottom=0.775, top=0.95, wspace=0.00, hspace=0.00, left=0.00, right=0.5)\n",
    "    gc2 = fig.add_gridspec(5, 4, bottom=0.04, top=0.95, wspace=0.00, hspace=0.05, left=0.5, right=1.0)\n",
    "\n",
    "    # Plot observations (always the same for all plots)\n",
    "    for i in range(len(input_slices)):\n",
    "        ax = fig.add_subplot(gs1[0, i])\n",
    "        input_slice = input_slices[i]\n",
    "        plot_precip_field(input_slice, geodata=metadata, colorbar=False, axis=\"off\", colormap_config=cmap_config)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.text(-0.05, 0.5, \"Observation\", fontsize=37, ha=\"center\", va=\"center\", rotation=90)\n",
    "        if i == 3:\n",
    "            ax.text(0.5, 1.05, f\"{moment_datetime}\", fontsize=37, ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        else:\n",
    "            ax.text(0.5, 1.05, f\"{-15 + (i * 5)} min\", fontsize=37, ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        clean_up_axes(ax)\n",
    "\n",
    "    for i in range(len(target_slices)):\n",
    "        ax = fig.add_subplot(gc2[0, i])\n",
    "        plot_precip_field(\n",
    "            target_slices[i], geodata=metadata, bbox=None, colorbar=False, axis=\"off\", colormap_config=cmap_config\n",
    "        )\n",
    "        ax.text(0.5, 1.05, f\"+{(i + 1) * 5} min\", fontsize=37, ha=\"center\", va=\"center\")\n",
    "        clean_up_axes(ax)\n",
    "\n",
    "    # Plot the models from current subset\n",
    "    for x, (model_name, output_slices) in enumerate(current_outputs.items(), start=1):\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Output slices shape: {output_slices.shape}\")\n",
    "        num_slices = min(len(output_slices), gc2.ncols)\n",
    "        for i in range(num_slices):\n",
    "            ax = fig.add_subplot(gc2[x, i])\n",
    "            plot_precip_field(\n",
    "                np.squeeze(output_slices[i]), geodata=metadata, colorbar=False, axis=\"off\", colormap_config=cmap_config\n",
    "            )\n",
    "            if i == 0:\n",
    "                ax.text(-0.05, 0.5, model_name, fontsize=37, ha=\"center\", va=\"center\", rotation=90)\n",
    "            clean_up_axes(ax)\n",
    "\n",
    "    # Add colorbar\n",
    "    cmap = cmap_config.cmap\n",
    "    norm = cmap_config.norm\n",
    "    bounds = cmap_config.bounds\n",
    "    cbaxes = fig.add_axes([0.3, 0.01, 0.4, 0.02])\n",
    "\n",
    "    cbar = fig.colorbar(\n",
    "        cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "        cax=cbaxes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=5,\n",
    "        shrink=0,\n",
    "        anchor=(0.5, 1.0),\n",
    "        panchor=(0.5, 0.0),\n",
    "        ticks=bounds,\n",
    "        extend=\"both\",\n",
    "        extendfrac=\"auto\",\n",
    "        spacing=\"uniform\",\n",
    "    )\n",
    "\n",
    "    cbar.ax.set_xlabel(r\"Rainfall intensity (mm h$^{-1}$)\", fontsize=37)\n",
    "    cbar.ax.tick_params(labelsize=37)\n",
    "\n",
    "    # Find existing files with similar pattern for this specific idx\n",
    "    existing_files = [f for f in os.listdir(directory) if f.startswith(f\"Forecast_{idx}_\")]\n",
    "    next_num = len(existing_files) + 1\n",
    "\n",
    "    outfile = os.path.join(directory, f\"Forecast_{idx}_{next_num}.png\")\n",
    "    plt.savefig(outfile, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved plot to {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:14.486158Z",
     "iopub.status.busy": "2024-11-14T03:15:14.485275Z",
     "iopub.status.idle": "2024-11-14T03:15:14.498871Z",
     "shell.execute_reply": "2024-11-14T03:15:14.498461Z"
    }
   },
   "outputs": [],
   "source": [
    "from pysteps import motion\n",
    "from pysteps.nowcasts import steps, linda\n",
    "from pysteps.motion.lucaskanade import dense_lucaskanade\n",
    "from pysteps.utils import transformation\n",
    "import torch\n",
    "\n",
    "\n",
    "class ForecastModel:\n",
    "    def __init__(self, rainrate_field, prediction_step, seed=None):\n",
    "        if isinstance(rainrate_field, torch.Tensor):\n",
    "            # check if input is of shape (4,1,256,256), then squeeze the second dimension\n",
    "            if rainrate_field.shape[1] == 1:\n",
    "                rainrate_field = rainrate_field.squeeze(1)  # shape transfer to (4, 256, 256)\n",
    "            self.rainrate_field = rainrate_field.cpu().numpy()  # transfer to np.ndarray\n",
    "\n",
    "        self.prediction_step = prediction_step\n",
    "        try:\n",
    "            self.advection = dense_lucaskanade(self.rainrate_field, verbose=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            self.advection = None\n",
    "\n",
    "        self.seed = seed\n",
    "        self.velocity = self.calculate_velocity_field()\n",
    "\n",
    "    def calculate_velocity_field(self):\n",
    "        oflow_method = motion.get_method(\"LK\")\n",
    "        return oflow_method(self.rainrate_field)\n",
    "\n",
    "    def get_steps_forecast(self):\n",
    "        # Process input data：Remove the second dimension and convert to np.ndarray\n",
    "        rainrate_field_db = self.rainrate_field\n",
    "\n",
    "        # using dB transfering\n",
    "        rainrate_field_db, _ = transformation.dB_transform(rainrate_field_db, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "        # Use inline if-else to control slicing\n",
    "        ar_order = 2  # Default autoregressive order for STEPS\n",
    "        required_frames = ar_order + 1  # STEPS requires at least 3 frames\n",
    "\n",
    "        precip_input = (\n",
    "            rainrate_field_db[: -self.prediction_step]\n",
    "            if rainrate_field_db.shape[0] > self.prediction_step\n",
    "            and rainrate_field_db.shape[0] - self.prediction_step >= required_frames\n",
    "            else rainrate_field_db\n",
    "        )\n",
    "\n",
    "        # use steps.forecast to predict\n",
    "        forecast_steps = steps.forecast(\n",
    "            precip_input,\n",
    "            self.velocity,\n",
    "            self.prediction_step,\n",
    "            20,\n",
    "            n_cascade_levels=6,\n",
    "            precip_thr=-10.0,\n",
    "            kmperpixel=2.0,\n",
    "            timestep=5,\n",
    "            noise_method=\"nonparametric\",\n",
    "            vel_pert_method=\"bps\",\n",
    "            mask_method=\"incremental\",\n",
    "            seed=self.seed,\n",
    "        )\n",
    "\n",
    "        # reversed dB transfering\n",
    "        forecast_steps = transformation.dB_transform(forecast_steps, threshold=-10.0, inverse=True)[0]\n",
    "\n",
    "        forecast_steps = np.mean(forecast_steps, axis=0)\n",
    "\n",
    "        # Process the output data: add second dimension and convert to torch.Tensor\n",
    "        forecast_steps = np.expand_dims(forecast_steps, axis=1)  # shape to (18, 1, 256, 256)\n",
    "        forecast_steps = torch.from_numpy(forecast_steps)  # transfer to torch.Tensor\n",
    "\n",
    "        return torch.where(torch.isnan(forecast_steps), torch.tensor(float(0)), forecast_steps)\n",
    "\n",
    "    def get_linda_forecast(self):\n",
    "        # Process the input data: remove the second dimension and convert to np.ndarray\n",
    "        rainrate_field_db = self.rainrate_field\n",
    "\n",
    "        # using dB transfering\n",
    "        rainrate_field_db, _ = transformation.dB_transform(rainrate_field_db, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "        # Use inline if-else to control slicing\n",
    "        ari_order = 2  # Default autoregressive order for LINDA\n",
    "        required_frames = ari_order + 2  # LINDA requires at least 4 frames\n",
    "\n",
    "        precip_input = (\n",
    "            rainrate_field_db[: -self.prediction_step]\n",
    "            if rainrate_field_db.shape[0] > self.prediction_step\n",
    "            and rainrate_field_db.shape[0] - self.prediction_step >= required_frames\n",
    "            else rainrate_field_db\n",
    "        )\n",
    "\n",
    "        # use linda.forecast to predict\n",
    "        forecast_linda = linda.forecast(\n",
    "            precip_input,\n",
    "            self.advection if self.advection is not None else self.velocity,\n",
    "            self.prediction_step,\n",
    "            max_num_features=15,\n",
    "            add_perturbations=False,\n",
    "            num_workers=8,\n",
    "            measure_time=True,\n",
    "        )[0]\n",
    "\n",
    "        # Process the output data: add second dimension and convert to torch.Tensor\n",
    "        forecast_linda = np.expand_dims(forecast_linda, axis=1)  # shape to (18, 1, 256, 256)\n",
    "        forecast_linda = torch.from_numpy(forecast_linda)  # transfer to torch.Tensor\n",
    "\n",
    "        return torch.where(torch.isnan(forecast_linda), torch.tensor(float(0)), forecast_linda)\n",
    "\n",
    "    def get_sprog_forecast(self):\n",
    "        rainrate_field_db, _ = transformation.dB_transform(\n",
    "            self.rainrate_field, self.metadata, threshold=0.1, zerovalue=-15.0\n",
    "        )\n",
    "        rainrate_thr, _ = transformation.dB_transform(np.array([0.5]), self.metadata, threshold=0.1, zerovalue=-15.0)\n",
    "        rainrate_field_db[~np.isfinite(rainrate_field_db)] = -15.0\n",
    "        rainrate_field_db = np.nan_to_num(rainrate_field_db, nan=-15.0).astype(np.float64)\n",
    "        forecast_sprog = sprog.forecast(\n",
    "            rainrate_field_db[: -self.prediction_step],\n",
    "            self.velocity,\n",
    "            self.prediction_step,\n",
    "            n_cascade_levels=6,\n",
    "            R_thr=rainrate_thr[0],\n",
    "        )\n",
    "        forecast_sprog, _ = transformation.dB_transform(forecast_sprog, threshold=-10.0, inverse=True)\n",
    "        forecast_sprog[forecast_sprog < 0.5] = 0.0\n",
    "        return forecast_sprog\n",
    "\n",
    "\n",
    "# model = ForecastModel(rainrate_field, 18, 42)\n",
    "\n",
    "# forecast_steps = model.get_steps_forecast()\n",
    "# forecast_linda = model.get_linda_forecast()\n",
    "\n",
    "# print(forecast_steps.shape)  # should be (18, 1, 256, 256)\n",
    "# print(forecast_linda.shape)  # should be (18, 1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T03:15:14.502347Z",
     "iopub.status.busy": "2024-11-14T03:15:14.501454Z",
     "iopub.status.idle": "2024-11-14T03:15:51.571580Z",
     "shell.execute_reply": "2024-11-14T03:15:51.571056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold timing results\n",
    "timing = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in sampled_ids:\n",
    "        print(\"Plotting Sample\", idx)\n",
    "        title = f\"Plotting Sample {idx}\"\n",
    "        if USE_CASA:\n",
    "            test_inputs, test_targets, frame_datetimes = test_data_loader.dataset[idx]\n",
    "            last_input_datetime = frame_datetimes[-1]\n",
    "            moment_datetime = last_input_datetime.strftime(\"%d %B, %Y - %H:%M\")\n",
    "        else:  # Nimrod\n",
    "            test_inputs, test_targets = test_data_loader.dataset[idx]\n",
    "            moment_datetime = \"Nimrod unspecified\"\n",
    "            metadata = None\n",
    "\n",
    "        # Convert NumPy arrays to PyTorch tensors and add batch dimension\n",
    "        test_inputs = torch.tensor(test_inputs).unsqueeze(0).to(device)\n",
    "        test_targets = torch.tensor(test_targets).unsqueeze(0).to(device)\n",
    "\n",
    "        print(\"Using ML models to predict\")\n",
    "        # Initialize dictionary to hold outputs with model names\n",
    "        test_outputs = {}\n",
    "        timing = {}\n",
    "        for model_name, model in models.items():\n",
    "            with timer(model_name):\n",
    "                model_output = model(test_inputs)\n",
    "                # remove the batch dimension\n",
    "                test_outputs[model_name] = model_output.squeeze(0).cpu().numpy()\n",
    "\n",
    "        # print(\"Using PySteps to predict\")\n",
    "\n",
    "        pysteps_model = ForecastModel(test_inputs.squeeze(0).squeeze(1), NUM_TARGET_FRAMES, 42)\n",
    "\n",
    "        with timer(\"STEPS\"):\n",
    "            test_outputs[\"STEPS\"] = pysteps_model.get_steps_forecast()\n",
    "\n",
    "        with timer(\"LINDA\"):\n",
    "            test_outputs[\"LINDA\"] = pysteps_model.get_linda_forecast()\n",
    "\n",
    "        # Proceed with plotting\n",
    "\n",
    "        print(\"Plotting\")\n",
    "        # Calculate how many plots we need (ceil division)\n",
    "        num_plots = (len(test_outputs) + 3) // 4  # +3 to round up\n",
    "\n",
    "        # Create multiple plots for each subset of models\n",
    "        for plot_idx in range(num_plots):\n",
    "            plot_data_and_save(\n",
    "                test_inputs,\n",
    "                test_targets,\n",
    "                test_outputs,\n",
    "                metadata,\n",
    "                directory=plot_output_path,\n",
    "                idx=idx,\n",
    "                moment_datetime=moment_datetime,\n",
    "                title=title,\n",
    "                model_subset_idx=plot_idx,\n",
    "            )  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
